{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "853a9461eb474a11870d97ad8ccd68ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08d49f32e4044854bd29275eae6897df",
              "IPY_MODEL_eff7057448c645d3b12148648088bc61",
              "IPY_MODEL_c90cba3af2d94113ae8b5d53f972d50b"
            ],
            "layout": "IPY_MODEL_de3fa5dbf5524423a76db2a5f34181b7"
          }
        },
        "08d49f32e4044854bd29275eae6897df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5816800466e4267b01a51b5a95700ca",
            "placeholder": "​",
            "style": "IPY_MODEL_64fdbd9811424eab9197e2f5e2a50a3d",
            "value": "100%"
          }
        },
        "eff7057448c645d3b12148648088bc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e0a180e5e2459882915ff504c69d02",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd3cc6293994414d9c9d62a743d329e8",
            "value": 111898327
          }
        },
        "c90cba3af2d94113ae8b5d53f972d50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f8830e305e41e6b1410bc83dc21359",
            "placeholder": "​",
            "style": "IPY_MODEL_a7b5e7e25cd049c9b0a428800df84318",
            "value": " 107M/107M [00:00&lt;00:00, 132MB/s]"
          }
        },
        "de3fa5dbf5524423a76db2a5f34181b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5816800466e4267b01a51b5a95700ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64fdbd9811424eab9197e2f5e2a50a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42e0a180e5e2459882915ff504c69d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3cc6293994414d9c9d62a743d329e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17f8830e305e41e6b1410bc83dc21359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b5e7e25cd049c9b0a428800df84318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of the code"
      ],
      "metadata": {
        "id": "UDF7WGbsClRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was used to generate images cycled back to the original age, both for young and old samples. Then, the folders that were used to store the cycled images are passed to the notebook for FID-KID calculation."
      ],
      "metadata": {
        "id": "0Lr-fsyECoJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Facenet - Used as Face Encoder"
      ],
      "metadata": {
        "id": "D5bjNyNwA04R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eVwJw6DT9X9Q",
        "outputId": "ba842228-56bb-496a-e987-1eb2687b48e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet_pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from facenet_pytorch)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<10.3.0,>=10.2.0 (from facenet_pytorch)\n",
            "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (2.32.3)\n",
            "Collecting torch<2.3.0,>=2.2.0 (from facenet_pytorch)\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision<0.18.0,>=0.17.0 (from facenet_pytorch)\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3.0,>=2.2.0->facenet_pytorch)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet_pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet_pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet_pytorch) (1.3.0)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet_pytorch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0 facenet_pytorch-2.6.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "c7a966413e38453488d0a3df8693e2e8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ],
      "metadata": {
        "id": "e8VoVn5_yMxo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWavLgHyDMwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293ecfe8-41c5-4eaa-ddf1-0bd0ee809331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/My\\ Drive/"
      ],
      "metadata": {
        "id": "NH2Si8DDElSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Folders for Generated Images"
      ],
      "metadata": {
        "id": "FLV8F1imyXQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cycled_young = '/content/drive/My Drive/Cycled_Young'\n",
        "cycled_old = '/content/drive/My Drive/Cycled_Old'"
      ],
      "metadata": {
        "id": "MzOp0qPd-X4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the folder if necessary\n",
        "os.makedirs(cycled_young, exist_ok=True)\n",
        "os.makedirs(cycled_old, exist_ok=True)"
      ],
      "metadata": {
        "id": "hHqwWB2QxH5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Brianna's Models"
      ],
      "metadata": {
        "id": "P_I5eKgSwje-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original (Baseline w/ MSE + Label Smoothing)"
      ],
      "metadata": {
        "id": "x7giE3OpwuiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cycled_young = '/content/drive/My Drive/BA_results/ORIGINAL/young'\n",
        "cycled_old = '/content/drive/My Drive/BA_results/ORIGINAL/old'"
      ],
      "metadata": {
        "id": "969lswryxWgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptual Loss"
      ],
      "metadata": {
        "id": "j_wrUJC6wv-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cycled_young = '/content/drive/My Drive/BA_results/PERCEPT/young'\n",
        "cycled_old = '/content/drive/My Drive/BA_results/PERCEPT/old'"
      ],
      "metadata": {
        "id": "_7du9kFuxW8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WCGAN"
      ],
      "metadata": {
        "id": "0pDZm-L-xUIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cycled_young = '/content/drive/My Drive/BA_results/WCGAN/young'\n",
        "cycled_old = '/content/drive/My Drive/BA_results/WCGAN/old'"
      ],
      "metadata": {
        "id": "Pqapi1A3xXgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generators"
      ],
      "metadata": {
        "id": "05Kke9Ijye3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definitions"
      ],
      "metadata": {
        "id": "buPGR4shyjNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATOR DEFINITION\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def up_conv(in_channels, out_channels, kernel_size, stride=1, padding=1,\n",
        "            scale_factor=2, norm='batch', activ=None):\n",
        "    \"\"\"Create a transposed-convolutional layer, with optional normalization.\"\"\"\n",
        "    layers = []\n",
        "    layers.append(nn.Upsample(scale_factor=scale_factor, mode='nearest'))\n",
        "    layers.append(nn.Conv2d(\n",
        "        in_channels, out_channels,\n",
        "        kernel_size, stride, padding, bias=norm is None\n",
        "    ))\n",
        "    if norm == 'batch':\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    elif norm == 'instance':\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "\n",
        "    if activ == 'relu':\n",
        "        layers.append(nn.ReLU())\n",
        "    elif activ == 'leaky':\n",
        "        layers.append(nn.LeakyReLU())\n",
        "    elif activ == 'tanh':\n",
        "        layers.append(nn.Tanh())\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size, stride=2, padding=1,\n",
        "         norm='batch', init_zero_weights=False, activ=None, discrim=True):\n",
        "    \"\"\"Create a convolutional layer, with optional normalization.\"\"\"\n",
        "    layers = []\n",
        "    conv_layer = nn.Conv2d(\n",
        "        in_channels=in_channels, out_channels=out_channels,\n",
        "        kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "        bias=norm is None\n",
        "    )\n",
        "    if init_zero_weights:\n",
        "        conv_layer.weight.data = 0.001 * torch.randn(\n",
        "            out_channels, in_channels, kernel_size, kernel_size\n",
        "        )\n",
        "    if discrim:\n",
        "        conv_layer = torch.nn.utils.spectral_norm(conv_layer)\n",
        "    layers.append(conv_layer)\n",
        "\n",
        "    if norm == 'batch':\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    elif norm == 'instance':\n",
        "        layers.append(nn.InstanceNorm2d(out_channels))\n",
        "\n",
        "    if activ == 'relu':\n",
        "        layers.append(nn.ReLU())\n",
        "    elif activ == 'leaky':\n",
        "        layers.append(nn.LeakyReLU())\n",
        "    elif activ == 'tanh':\n",
        "        layers.append(nn.Tanh())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, noise_size, conv_dim=128):\n",
        "        super().__init__()\n",
        "        self.up_conv1 = conv(in_channels=noise_size, out_channels=(conv_dim * 4), kernel_size=4, stride=1, padding=3,\n",
        "                             norm='batch', init_zero_weights=False, activ='relu', discrim=False)\n",
        "        self.up_conv2 = up_conv(in_channels=(conv_dim * 4), out_channels=(conv_dim * 2), kernel_size=3, stride=1,\n",
        "                                padding=1, scale_factor=2, norm='batch', activ='relu')\n",
        "        self.up_conv3 = up_conv(in_channels=(conv_dim * 2), out_channels=conv_dim, kernel_size=3, stride=1, padding=1,\n",
        "                                scale_factor=2, norm='batch', activ='relu')\n",
        "        self.up_conv4 = up_conv(in_channels=conv_dim, out_channels=(conv_dim // 2), kernel_size=3, stride=1, padding=1,\n",
        "                                scale_factor=2, norm='batch', activ='relu')\n",
        "        self.up_conv5 = up_conv(in_channels=(conv_dim // 2), out_channels=(conv_dim // 4), kernel_size=3, stride=1,\n",
        "                                padding=1, scale_factor=2, norm='batch', activ='relu')\n",
        "        self.up_conv6 = up_conv(in_channels=(conv_dim // 4), out_channels=3, kernel_size=3, stride=1,\n",
        "                                padding=1, scale_factor=2, norm=None, activ='tanh')\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = self.up_conv1(z)\n",
        "        z = self.up_conv2(z)\n",
        "        z = self.up_conv3(z)\n",
        "        z = self.up_conv4(z)\n",
        "        z = self.up_conv5(z)\n",
        "        z = self.up_conv6(z)\n",
        "        return z"
      ],
      "metadata": {
        "id": "E7yacePt6vZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load from State Dict"
      ],
      "metadata": {
        "id": "xRQWgFPhynDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import InceptionResnetV1\n",
        "from PIL import Image\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from torchvision import transforms\n",
        "\n",
        "def add_noise(image_encodings):\n",
        "    num_samples = image_encodings.shape[0]\n",
        "    noise_vectors = torch.randn((num_samples, 128), device=device)\n",
        "    # noise_vectors = torch.randn((num_samples, 64), device=device)\n",
        "    augmented_noise = torch.cat([image_encodings, noise_vectors], dim=1).unsqueeze(2).unsqueeze(3)\n",
        "    return augmented_noise\n",
        "\n",
        "# Create generator instances and load the parameters from state dict\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformation for images to be compatible with the generators\n",
        "transform = transforms.Compose([\n",
        "                transforms.Resize((128, 128), Image.BICUBIC),\n",
        "                transforms.CenterCrop((128, 128)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ])\n",
        "\n",
        "# Face encoder\n",
        "face_encoder = InceptionResnetV1(pretrained=\"vggface2\").to(device).eval()\n",
        "\n",
        "# Load the generators\n",
        "generator_young_to_old = Generator(noise_size=640).to(device)\n",
        "# generator_young_to_old = Generator(noise_size=576).to(device)\n",
        "# generator_young_to_old.load_state_dict(torch.load(\"/content/drive/My Drive/g_oty_updated/g_yto.pth\"))\n",
        "generator_young_to_old.load_state_dict(torch.load(\"/content/drive/My Drive/all_models_BA/ORIGINAL_g_yto.pth\", map_location=torch.device('cuda'))) # ORIGINAL\n",
        "# generator_young_to_old.load_state_dict(torch.load(\"/content/drive/My Drive/all_models_BA/percept_g_yto.pth\", map_location=torch.device('cuda'))) # PERCEPT\n",
        "# generator_young_to_old.load_state_dict(torch.load(\"/content/drive/My Drive/all_models_BA/wcgan_g_yto.pth\", map_location=torch.device('cuda'))) # WCGAN\n",
        "# generator_young_to_old.load_state_dict(torch.load(\"/content/drive/My Drive/Updated Weights and Photos/updated_weights/wcgan_g_yto.pth\", map_location=torch.device('cuda'))) # NEW WCGAN\n",
        "# generator_young_to_old.load_state_dict(torch.load(\"/content/drive/My Drive/Updated Weights and Photos/updated_weights/percept_g_yto.pth\", map_location=torch.device('cuda'))) # NEW PERCEPT\n",
        "# generator_young_to_old.load_state_dict(torch.load(\"/content/drive/My Drive/Updated Weights and Photos/updated_weights/decreased_noise_g_yto.pth\", map_location=torch.device('cuda'))) # REDUCED NOISE\n",
        "\n",
        "\n",
        "generator_old_to_young = Generator(noise_size=640).to(device)\n",
        "# generator_old_to_young = Generator(noise_size=576).to(device)\n",
        "# generator_old_to_young.load_state_dict(torch.load(\"/content/drive/My Drive/g_oty_updated/g_oty.pth\"))\n",
        "generator_old_to_young.load_state_dict(torch.load(\"/content/drive/My Drive/all_models_BA/ORIGINAL_g_oty.pth\", map_location=torch.device('cuda'))) # ORIGINAL\n",
        "# generator_old_to_young.load_state_dict(torch.load(\"/content/drive/My Drive/all_models_BA/percept_g_oty.pth\", map_location=torch.device('cuda'))) # PERCEPT\n",
        "# generator_old_to_young.load_state_dict(torch.load(\"/content/drive/My Drive/all_models_BA/wcgan_g_oty.pth\", map_location=torch.device('cuda'))) # WCGAN\n",
        "# generator_old_to_young.load_state_dict(torch.load(\"/content/drive/My Drive/Updated Weights and Photos/updated_weights/wcgan_g_oty.pth\", map_location=torch.device('cuda'))) # NEW WCGAN\n",
        "# generator_old_to_young.load_state_dict(torch.load(\"/content/drive/My Drive/Updated Weights and Photos/updated_weights/percept_g_oty.pth\", map_location=torch.device('cuda'))) # NEW PERCEPT\n",
        "# generator_old_to_young.load_state_dict(torch.load(\"/content/drive/My Drive/Updated Weights and Photos/updated_weights/decreased_noise_g_oty.pth\", map_location=torch.device('cuda'))) # REDUCED NOISE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "853a9461eb474a11870d97ad8ccd68ce",
            "08d49f32e4044854bd29275eae6897df",
            "eff7057448c645d3b12148648088bc61",
            "c90cba3af2d94113ae8b5d53f972d50b",
            "de3fa5dbf5524423a76db2a5f34181b7",
            "d5816800466e4267b01a51b5a95700ca",
            "64fdbd9811424eab9197e2f5e2a50a3d",
            "42e0a180e5e2459882915ff504c69d02",
            "fd3cc6293994414d9c9d62a743d329e8",
            "17f8830e305e41e6b1410bc83dc21359",
            "a7b5e7e25cd049c9b0a428800df84318"
          ]
        },
        "id": "_ho-wfbRxZkL",
        "outputId": "fab9eccc-fecc-4049-aeb4-7314e339511e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "853a9461eb474a11870d97ad8ccd68ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cycle for Young Images"
      ],
      "metadata": {
        "id": "9y4bf0pyywiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUNG IMAGES\n",
        "import numpy as np\n",
        "\n",
        "young_folder = \"/content/drive/My Drive/young_folder\"\n",
        "total_young_count = 0\n",
        "\n",
        "for img_name in os.listdir(young_folder):\n",
        "\n",
        "    # Path to image\n",
        "    img_path = os.path.join(young_folder, img_name)\n",
        "\n",
        "    # APPLY CYCLE AND SAVE BACK\n",
        "    young_img = Image.open(img_path).convert(\"RGB\") # Load image\n",
        "    young_img = transform(young_img).unsqueeze(0).to(device) # Transform the image for model\n",
        "    young_encoding = add_noise(face_encoder(young_img)) # Encoding\n",
        "    young_to_old = generator_young_to_old(young_encoding) # Young to old\n",
        "    re_young = generator_old_to_young(add_noise(face_encoder(young_to_old))) # Cycled back to young\n",
        "    re_young_img = (re_young[0] + 1) / 2\n",
        "    re_young_path = os.path.join(cycled_young, img_name)\n",
        "    save_image(re_young_img, re_young_path) # Save the cycled image to cycled folder\n",
        "\n",
        "    total_young_count += 1\n",
        "    print(\"Current young count:\", total_young_count)"
      ],
      "metadata": {
        "id": "2tO7Q6avrLZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cycle for Old Images"
      ],
      "metadata": {
        "id": "krT9Vk7ly09I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OLD IMAGES\n",
        "\n",
        "old_folder = \"/content/drive/My Drive/old_folder\"\n",
        "total_old_count = 0\n",
        "\n",
        "for img_name in os.listdir(old_folder):\n",
        "\n",
        "    # Path to image\n",
        "    img_path = os.path.join(old_folder, img_name)\n",
        "\n",
        "    # APPLY CYCLE AND SAVE BACK\n",
        "    old_img = Image.open(img_path).convert(\"RGB\") # Load image\n",
        "    old_img = transform(old_img).unsqueeze(0).to(device) # Transform the image for model\n",
        "    old_encoding = add_noise(face_encoder(old_img)) # Encoding\n",
        "    old_to_young = generator_old_to_young(old_encoding) # Old to young\n",
        "    re_old = generator_young_to_old(add_noise(face_encoder(old_to_young))) # Cycled back to old\n",
        "    re_old_img = (re_old[0] + 1) / 2\n",
        "    re_old_path = os.path.join(cycled_old, img_name)\n",
        "    save_image(re_old_img, re_old_path) # Save the cycled image to cycled folder\n",
        "\n",
        "    total_old_count += 1\n",
        "    print(\"Current old count:\", total_old_count)"
      ],
      "metadata": {
        "id": "B-2E-TYlHCdT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}